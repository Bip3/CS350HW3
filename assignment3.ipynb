{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245217cc",
   "metadata": {},
   "source": [
    "# Assignment: SVD Preprocessing on MNIST with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffa444",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "In this assignment, you will apply **Singular Value Decomposition (SVD)** as a preprocessing step to the **MNIST dataset** and train a **logistic regression classifier**. You will compare the model performance and training time when using different levels of SVD for dimensionality reduction.\n",
    "\n",
    "In this assignment, you will need to:\n",
    "1. Load the MNIST dataset and normalize it.\n",
    "2. Perform SVD and reduce the dimensions of the data.\n",
    "3. Train a logistic regression model on the original and SVD-reduced data.\n",
    "4. Measure and compare the training time and accuracy of the model with varying SVD components.\n",
    "5. Plot the results and analyze how SVD impacts the performance and efficiency of the model.\n",
    "\n",
    "***\n",
    "Your tasks include:\n",
    "1. Implement SVD algorithm. You are not allowed to directly use SVD implemented by other packages, but you may use functions in NumPy. (Part 2)\n",
    "2. Explore the accuracy and time performance from different numbers of SVD components. (Part 4)\n",
    "3. Visualize the accuracy, time performance and top 5 singular vectors in the dataset, analyze and explain which number of SVD component looks best to you? (Part 4,5&6) Hint: singular vectors should be reshaped to 28x28 images for visualization.\n",
    "***\n",
    "**Note that you may not import any other function or package.** Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e10cb3",
   "metadata": {},
   "source": [
    "## Part 1: Load the MNIST dataset and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f2d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# Normalize the data\n",
    "X = X / 255.0\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8572d",
   "metadata": {},
   "source": [
    "## Part 2: Implement SVD for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c37c45f-1841-4d77-8317-94b262e40c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def svd(X):\n",
    "    \"\"\"\n",
    "    Compute the Singular Value Decomposition (SVD) of matrix X from scratch.\n",
    "    X = U * S * V^T\n",
    "    \"\"\"\n",
    "    # Step 1: Compute the covariance matrix A^T * A\n",
    "    A_T_A = np.dot(X.T, X)\n",
    "\n",
    "    # Step 2: Compute eigenvalues and eigenvectors of A^T * A (for V and S)\n",
    "    eigenvalues, V = np.linalg.eig(A_T_A)\n",
    "\n",
    "    # Step 3: Sort the eigenvalues and eigenvectors by decreasing eigenvalue magnitude\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    V = V[:, idx]\n",
    "\n",
    "    # Step 4: Compute singular values (S is the square root of eigenvalues)\n",
    "    singular_values = np.sqrt(np.abs(eigenvalues))\n",
    "    \n",
    "    # Step 5: Compute U using U = A * V * Î£^-1\n",
    "    # Filter out eigenvalues that are too small (to avoid division by zero)\n",
    "    tolerance = 1e-10\n",
    "    singular_values_inv = np.array([1/s if s > tolerance else 0 for s in singular_values])\n",
    "    Sigma_inv = np.diag(singular_values_inv)\n",
    "    \n",
    "    U = np.dot(X, np.dot(V, Sigma_inv))\n",
    "\n",
    "    # Step 6: Construct the S matrix as a diagonal matrix of singular values\n",
    "    S = np.diag(singular_values)\n",
    "\n",
    "    return U, S, V.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3bd59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svd_custom(X_train, X_test, n_components):\n",
    "    U, S, VT = svd(X_train)\n",
    "\n",
    "    U_k = U[:, :n_components]\n",
    "    S_k = np.diag(S[:n_components])\n",
    "    VT_k = VT[:n_components, :]\n",
    "\n",
    "    X_train_reduced = np.dot(U_k, S_k)\n",
    "    X_test_reduced = np.dot(X_test, VT_k.T)\n",
    "\n",
    "    return X_train_reduced, X_test_reduced\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc31b1a-b77b-4270-bf69-d6d3f5e9ccf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.01345996e-01  7.67938141e-01 -8.12578946e-08]\n",
      " [-2.48568753e-01  4.88071281e-01 -5.07570803e-08]\n",
      " [-3.95791510e-01  2.08204420e-01 -1.93249434e-08]\n",
      " [-5.43014267e-01 -7.16624412e-02  1.39698386e-08]\n",
      " [-6.90237024e-01 -3.51529302e-01  3.98140401e-08]]\n",
      "[[3.51826483e+01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47690770e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.18272661e-07]]\n",
      "[[-0.51927261 -0.57552072 -0.63176883]\n",
      " [-0.75079244 -0.04592639  0.65893966]\n",
      " [ 0.40824829 -0.81649658  0.40824829]]\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]\n",
      " [13. 14. 15.]]\n"
     ]
    }
   ],
   "source": [
    "#Checking for correct implementation of SVD\n",
    "X = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9],\n",
    "              [10, 11, 12],\n",
    "              [13, 14, 15]])\n",
    "U, S, VT = svd(X)\n",
    "print(U)\n",
    "print(S)\n",
    "print(VT)\n",
    "\n",
    "print(np.matmul(np.matmul(U, S), VT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a7a9d",
   "metadata": {},
   "source": [
    "## Part 3: Train Logistic Regression and Measure Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbfc0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train logistic regression and track training time\n",
    "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    model = LogisticRegression(max_iter=1000, solver='saga', random_state=42, multi_class='multinomial')\n",
    "    \n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, training_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e557a05",
   "metadata": {},
   "source": [
    "## Part 4: Experiment with Different Levels of SVD\n",
    "\n",
    "Now, apply SVD with varying numbers of components and observe how the dimensionality reduction impacts the model's performance. Record both the accuracy and training time for each number of components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a460725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models with different levels of SVD preprocessing...\n",
      "Applying custom SVD with 784 components...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  0.72365219 -11.01953575 -10.31621056 ...  -1.07456201 -12.88511593\n  -3.99237126].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m X_train_svd, X_test_svd \u001b[38;5;241m=\u001b[39m apply_svd_custom(X_train, X_test, n_components )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Apply SVD to the training and test sets\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Call apply_svd_custom() here...\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the logistic regression model and get accuracy and training time\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m accuracy, training_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_svd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_svd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD components: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m, in \u001b[0;36mtrain_logistic_regression\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Measure training time\u001b[39;00m\n\u001b[0;32m      6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  0.72365219 -11.01953575 -10.31621056 ...  -1.07456201 -12.88511593\n  -3.99237126].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "svd_components = [784]  # You need to decide what number to search...\n",
    "\n",
    "# Store the results\n",
    "results = []\n",
    "\n",
    "print(\"Training models with different levels of SVD preprocessing...\")\n",
    "for n_components in svd_components:\n",
    "    print(f\"Applying custom SVD with {n_components} components...\")\n",
    "\n",
    "    X_train_svd, X_test_svd = apply_svd_custom(X_train, X_test, n_components )\n",
    "    # Apply SVD to the training and test sets\n",
    "    # Call apply_svd_custom() here...\n",
    "    \n",
    "    # Train the logistic regression model and get accuracy and training time\n",
    "    accuracy, training_time = train_logistic_regression(X_train_svd, y_train, X_test_svd, y_test)\n",
    "        \n",
    "    print(f\"SVD components: {n_components}, Accuracy: {accuracy:.4f}, Training time: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7aca12",
   "metadata": {},
   "source": [
    "## Part 5: Visualize and Analyze the Results\n",
    "\n",
    "Finally, plot the accuracy, training time as a function of the number of SVD components, and top 5 singular vectors. This will help you understand the trade-off between dimensionality reduction, accuracy, and model training time, and how SVD generally works. Hint: singular vectors should be reshaped to 28x28 images for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your implementation here...\n",
    "## You may add necessary lines in Part 4 to access data for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210569a",
   "metadata": {},
   "source": [
    "## Part 6: Analyze / Conclusion \n",
    "\n",
    "YOUR ANSWER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f043c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
